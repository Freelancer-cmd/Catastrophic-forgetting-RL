{
    "agent": {
        "__class__": "<class 'rl_agents.agents.deep_q_network.pytorch.DQNAgent'>",
        "batch_size": 64,
        "device": "cuda:best",
        "double": true,
        "exploration": {
            "final_temperature": 0.05,
            "method": "EpsilonGreedy",
            "tau": 6000,
            "temperature": 1.0
        },
        "gamma": 0.99,
        "loss_function": "l2",
        "memory_capacity": 15000,
        "model": {
            "attention_layer": {
                "dropout_factor": 0,
                "feature_size": 64,
                "heads": 1,
                "type": "EgoAttention"
            },
            "embedding_layer": {
                "activation": "RELU",
                "in": 7,
                "layers": [
                    64,
                    64
                ],
                "out": null,
                "reshape": false,
                "type": "MultiLayerPerceptron"
            },
            "in": 105,
            "layers": [
                256,
                256
            ],
            "others_embedding_layer": {
                "activation": "RELU",
                "in": 7,
                "layers": [
                    64,
                    64
                ],
                "out": null,
                "reshape": false,
                "type": "MultiLayerPerceptron"
            },
            "out": 5,
            "output_layer": {
                "activation": "RELU",
                "in": 64,
                "layers": [
                    64,
                    64
                ],
                "out": 5,
                "reshape": false,
                "type": "MultiLayerPerceptron"
            },
            "presence_feature_idx": 0,
            "self_attention_layer": null,
            "type": "EgoAttentionNetwork"
        },
        "n_steps": 1,
        "optimizer": {
            "k": 5,
            "lr": 0.0005,
            "type": "ADAM",
            "weight_decay": 0
        },
        "target_update": 512
    },
    "env": {
        "__class__": "<class 'gymnasium.wrappers.common.OrderEnforcing'>",
        "_action_space": "None",
        "_cached_spec": "None",
        "_disable_render_order_enforcing": "False",
        "_has_reset": "True",
        "_metadata": "None",
        "_observation_space": "None",
        "_saved_kwargs": "{'disable_render_order_enforcing': False}",
        "env": "<PassiveEnvChecker<HighwayEnv<highway-v0>>>",
        "id": "highway-v0",
        "import_module": "highway_env"
    }
}